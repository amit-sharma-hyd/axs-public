{"nbformat_minor": 0, "cells": [{"execution_count": 36, "cell_type": "code", "source": "\"\"\"\nBeyond Beating the Benchmark \nSearch Results Relevance @ Kaggle\n__author__ : Amit Sharma\n\n\"\"\"\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.svm import SVC\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import decomposition, pipeline, metrics, grid_search\nfrom sklearn import cross_validation\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom bs4 import BeautifulSoup\n\n\npd.set_option('display.width', 5000) \npd.set_option('display.max_columns', 60) \n\ntrain = pd.read_csv('C:\\\\axs\\\\work\\\\kaggle\\\\crowdflower\\\\input\\\\train.csv')\ntest = pd.read_csv('C:\\\\axs\\\\work\\\\kaggle\\\\crowdflower\\\\input\\\\test.csv')\n\n# we dont need ID columns\nidx = test.id.values.astype(int)\ntrain = train.drop('id', axis=1)\ntest = test.drop('id', axis=1)\n\n# create labels. drop useless columns\ny = train.median_relevance.values\ntrain = train.drop(['median_relevance', 'relevance_variance'], axis=1)", "outputs": [], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 37, "cell_type": "code", "source": "# The following 3 functions have been taken from Ben Hamner's github repository\n# https://github.com/benhamner/Metrics\ndef confusion_matrix(rater_a, rater_b, min_rating=None, max_rating=None):\n    \"\"\"\n    Returns the confusion matrix between rater's ratings\n    \"\"\"\n    assert(len(rater_a) == len(rater_b))\n    if min_rating is None:\n        min_rating = min(rater_a + rater_b)\n    if max_rating is None:\n        max_rating = max(rater_a + rater_b)\n    num_ratings = int(max_rating - min_rating + 1)\n    conf_mat = [[0 for i in range(num_ratings)]\n                for j in range(num_ratings)]\n    for a, b in zip(rater_a, rater_b):\n        conf_mat[a - min_rating][b - min_rating] += 1\n    return conf_mat\n\n\ndef histogram(ratings, min_rating=None, max_rating=None):\n    \"\"\"\n    Returns the counts of each type of rating that a rater made\n    \"\"\"\n    if min_rating is None:\n        min_rating = min(ratings)\n    if max_rating is None:\n        max_rating = max(ratings)\n    num_ratings = int(max_rating - min_rating + 1)\n    hist_ratings = [0 for x in range(num_ratings)]\n    for r in ratings:\n        hist_ratings[r - min_rating] += 1\n    return hist_ratings\n\n\ndef quadratic_weighted_kappa(y, y_pred):\n    \"\"\"\n    Calculates the quadratic weighted kappa\n    axquadratic_weighted_kappa calculates the quadratic weighted kappa\n    value, which is a measure of inter-rater agreement between two raters\n    that provide discrete numeric ratings.  Potential values range from -1\n    (representing complete disagreement) to 1 (representing complete\n    agreement).  A kappa value of 0 is expected if all agreement is due to\n    chance.\n    quadratic_weighted_kappa(rater_a, rater_b), where rater_a and rater_b\n    each correspond to a list of integer ratings.  These lists must have the\n    same length.\n    The ratings should be integers, and it is assumed that they contain\n    the complete range of possible ratings.\n    quadratic_weighted_kappa(X, min_rating, max_rating), where min_rating\n    is the minimum possible rating, and max_rating is the maximum possible\n    rating\n    \"\"\"\n    rater_a = y\n    rater_b = y_pred\n    min_rating=None\n    max_rating=None\n    rater_a = np.array(rater_a, dtype=int)\n    rater_b = np.array(rater_b, dtype=int)\n    assert(len(rater_a) == len(rater_b))\n    if min_rating is None:\n        min_rating = min(min(rater_a), min(rater_b))\n    if max_rating is None:\n        max_rating = max(max(rater_a), max(rater_b))\n    conf_mat = confusion_matrix(rater_a, rater_b,\n                                min_rating, max_rating)\n    num_ratings = len(conf_mat)\n    num_scored_items = float(len(rater_a))\n\n    hist_rater_a = histogram(rater_a, min_rating, max_rating)\n    hist_rater_b = histogram(rater_b, min_rating, max_rating)\n\n    numerator = 0.0\n    denominator = 0.0\n\n    for i in range(num_ratings):\n        for j in range(num_ratings):\n            expected_count = (hist_rater_a[i] * hist_rater_b[j]\n                              / num_scored_items)\n            d = pow(i - j, 2.0) / pow(num_ratings - 1, 2.0)\n            numerator += d * conf_mat[i][j] / num_scored_items\n            denominator += d * expected_count / num_scored_items\n\n    return (1.0 - numerator / denominator)\n\nkappa_scorer = metrics.make_scorer(quadratic_weighted_kappa, greater_is_better = True)\n", "outputs": [], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 38, "cell_type": "code", "source": "def query_title_common(row):\n    return (set(row['query'].split()) & set(row['product_title'].split()))\n\ndef query_desc_common(row):\n    return (set(row['query'].split()) & set(row['pdesc'].split()))\n\ndef addFeatures(df):\n    df['query'] = df['query'].astype('str')\n    df['product_title'] = df['product_title'].astype('str')\n    df['product_description'] = df['product_description'].astype('str')\n    # Lowercase everything\n    df['query'] = df['query'].str.lower()\n    df['product_title'] = df['product_title'].str.lower()\n    df['product_description'] = df['product_description'].str.lower()\n\n    df['pdesc'] = map(lambda x: BeautifulSoup(''.join(x)).text, df['product_description'])\n\n    df['query_title'] = df.apply(query_title_common,axis=1)\n    df['query_title_nwords'] = df['query_title'].str.len()\n    df['title_nwords'] = df['product_title'].str.split().str.len()\n    df['query_nwords'] = df['query'].str.split().str.len()\n    df['query_title_match'] = df['query_title_nwords']/df['query_nwords']\n\n    df['query_desc'] = df.apply(query_desc_common,axis=1)\n    df['query_desc_nwords'] = df['query_desc'].str.len()\n    df['desc_nwords'] = df['pdesc'].str.split().str.len()\n    df['query_nwords'] = df['query'].str.split().str.len()\n    df['query_desc_match'] = df['query_desc_nwords']/df['query_nwords']\n\n    X=pd.DataFrame(df[['query', 'product_title', 'pdesc', 'query_nwords','title_nwords',\n             'query_title_nwords','query_title_match', 'desc_nwords','query_desc_nwords','query_desc_match']])\n    X['query_len'] = df['query'].str.len()\n    X['ptitle_len'] = df['product_title'].str.len()\n    X['query_title_match'] = (X['query_title_nwords']+0.00001)/X['query_nwords']\n    X['ptitle_size_over_query'] = X['ptitle_len']/X['query_len']\n    X['query'] = X['query'].astype(str)\n\n\n    X['query_len'] = df['query'].str.len()\n    X['pdesc_len'] = df['pdesc'].str.len()\n    X['query_desc_match'] = (X['query_desc_nwords']+0.00001)/X['query_nwords']\n    X['pdesc_size_over_query'] = X['pdesc_len']/X['query_len']\n\n    # Create dummy columns for categorical variable as scikit does not understand factors\n    dummyDF = pd.get_dummies(X['query'])\n    dummyDF= dummyDF.astype(bool)\n    X = pd.concat([X,dummyDF],axis=1)\n    \n    return (X)", "outputs": [], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 39, "cell_type": "code", "source": "train = addFeatures(train)\ntest = addFeatures(test)", "outputs": [{"output_type": "stream", "name": "stderr", "text": "C:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:189: UserWarning: \"http://i104.photobucket.com/albums/m175/champions_on_display/wincraft2013/januaryb/65527\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\nC:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:189: UserWarning: \"http://i104.photobucket.com/albums/m175/champions_on_display/wincraft2013/januarya/14146012.jpg\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n"}], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 40, "cell_type": "code", "source": "#Use SVM based learning \n# do some lambda magic on text columns\ntraindata = list(train.apply(lambda x:'%s %s' % (x['query'],x['product_title']),axis=1))\ntestdata = list(test.apply(lambda x:'%s %s' % (x['query'],x['product_title']),axis=1))\n\n# the infamous tfidf vectorizer (Do you remember this one?)\ntfv = TfidfVectorizer(min_df=3,  max_features=None, \n        strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n        ngram_range=(1, 5), use_idf=1,smooth_idf=1,sublinear_tf=1,\n        stop_words = 'english')\n\n# Fit TFIDF\ntfv.fit(traindata)\nX =  tfv.transform(traindata) \nX_test = tfv.transform(testdata)\n\n# Initialize SVD\nsvd = TruncatedSVD()\n\n# Initialize the standard scaler \nscl = StandardScaler()\n\n# We will use SVM here..\nsvm_model = SVC()\n\n# Create the pipeline\nclf = pipeline.Pipeline([('svd', svd),\n                         ('scl', scl),\n                         ('svm', svm_model)])\n\n# Create a parameter grid to search for best parameters for everything in the pipeline\nparam_grid = {'svd__n_components' : [400],\n              'svm__C': [12]}\n\n# Model Code - Run the model\n\n# Kappa Scorer \nkappa_scorer = metrics.make_scorer(quadratic_weighted_kappa, greater_is_better = True)\n\n# Initialize Grid Search Model\nmodel = grid_search.GridSearchCV(estimator = clf, param_grid=param_grid, scoring=kappa_scorer,\n                                 verbose=10, n_jobs=1, iid=True, refit=True, cv=2)\n\n# Fit Grid Search Model\nmodel.fit(X, y)\nprint(\"Best score: %0.3f\" % model.best_score_)\nprint(\"Best parameters set:\")\nbest_parameters = model.best_estimator_.get_params()\nfor param_name in sorted(param_grid.keys()):\n    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n\n# Get best model\nbest_model = model.best_estimator_\n\n\ntrainPred = best_model.predict(X)\ntestPred = best_model.predict(X_test)\n\ntrainX = pd.DataFrame(train)\ntestX = pd.DataFrame(test)\ntrain['model1_Pred'] = trainPred\ntest['model1_Pred'] = testPred", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n[CV] svm__C=12, svd__n_components=400 ................................\n[CV] ....... svm__C=12, svd__n_components=400, score=0.568257 -  22.8s\n[CV] svm__C=12, svd__n_components=400 ................................\n[CV] ....... svm__C=12, svd__n_components=400, score=0.549040 -  23.8s"}, {"output_type": "stream", "name": "stderr", "text": "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:   22.8s\n[Parallel(n_jobs=1)]: Done   2 jobs       | elapsed:   46.7s\n"}, {"output_type": "stream", "name": "stdout", "text": "\nBest score: 0.559\nBest parameters set:\n\tsvd__n_components: 400\n\tsvm__C: 12\n"}, {"output_type": "stream", "name": "stderr", "text": "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   46.7s finished\n"}], "metadata": {"scrolled": true, "collapsed": false, "trusted": true}}, {"execution_count": 41, "cell_type": "code", "source": "#TODO pdesc not used yet\ntrain = train.drop(['query', 'product_title', 'pdesc'], axis=1)\ntest = test.drop(['query', 'product_title', 'pdesc'], axis=1)", "outputs": [], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 42, "cell_type": "code", "source": "clf = GradientBoostingClassifier(n_estimators=500, learning_rate=0.5, max_depth=1, random_state=0).fit(train, y)\nscores = cross_validation.cross_val_score(clf, train, y, scoring=kappa_scorer, cv=10)\nscores", "outputs": [{"execution_count": 42, "output_type": "execute_result", "data": {"text/plain": "array([ 0.91209423,  0.8877413 ,  0.90756895,  0.91221159,  0.91673044,\n        0.89017358,  0.89749214,  0.90302268,  0.88764204,  0.91045196])"}, "metadata": {}}], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 43, "cell_type": "code", "source": "test[:3]", "outputs": [{"execution_count": 43, "output_type": "execute_result", "data": {"text/plain": "   query_nwords  title_nwords  query_title_nwords  query_title_match  desc_nwords  query_desc_nwords  query_desc_match  query_len  ptitle_len  ptitle_size_over_query  pdesc_len  pdesc_size_over_query 16 gb memory card 8 ounce mason jars acoustic guitar clamp adidas fragance adidas pants an extremely goofy movie anime necklace apple iphone 32 gb otterbox aqua shoes aroma diffuser assassinss creed aveeno shampoo barbie baseball cleats baseball photo frame batman beats headphones bedspreads     ...     vanity fair bras vans backpack victoria secret pink shorts victorias secret lace gown videogames ps4 volcom short waffle maker wall clocks wall mirrors watch women fossil werewolf costume white dress white jeans white plain dinner set    wii wii gamepad wii microphone wine rack wired xbox 360 controller wireless mouse workout clothes for women wreck it ralph yankee candle yankees yellow dress yoga mat yoga pants  zippo zippo hand warmer model1_Pred\n0             2             5                   2           1.000005            1                  0          0.000005         16          31                1.937500          3               0.187500             False              False                 False           False        False                    False          False                       False      False          False            False          False  False           False                False  False            False      False     ...                False         False                       False                      False          False        False        False       False        False              False            False       False       False                  False  False       False          False     False                     False          False                     False          False         False   False        False    False      False  False             False           4\n1             3            12                   2           0.666670            1                  0          0.000003         21          79                3.761905          3               0.142857             False              False                 False           False        False                    False          False                       False      False          False            False          False  False           False                False  False            False      False     ...                False         False                       False                      False          False        False        False       False        False              False            False       False       False                  False  False       False          False     False                     False          False                     False          False         False   False        False    False      False  False             False           4\n2             3             5                   3           1.000003           42                  3          1.000003         19          30                1.578947        227              11.947368             False              False                 False           False        False                    False          False                       False      False          False            False          False  False           False                False  False            False      False     ...                False         False                       False                      False          False        False        False       False        False              False            False       False       False                  False  False       False          False     False                     False          False                     False          False         False   False        False    False      False  False             False           3\n\n[3 rows x 274 columns]", "text/html": "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>query_nwords</th>\n      <th>title_nwords</th>\n      <th>query_title_nwords</th>\n      <th>query_title_match</th>\n      <th>desc_nwords</th>\n      <th>query_desc_nwords</th>\n      <th>query_desc_match</th>\n      <th>query_len</th>\n      <th>ptitle_len</th>\n      <th>ptitle_size_over_query</th>\n      <th>pdesc_len</th>\n      <th>pdesc_size_over_query</th>\n      <th>16 gb memory card</th>\n      <th>8 ounce mason jars</th>\n      <th>acoustic guitar clamp</th>\n      <th>adidas fragance</th>\n      <th>adidas pants</th>\n      <th>an extremely goofy movie</th>\n      <th>anime necklace</th>\n      <th>apple iphone 32 gb otterbox</th>\n      <th>aqua shoes</th>\n      <th>aroma diffuser</th>\n      <th>assassinss creed</th>\n      <th>aveeno shampoo</th>\n      <th>barbie</th>\n      <th>baseball cleats</th>\n      <th>baseball photo frame</th>\n      <th>batman</th>\n      <th>beats headphones</th>\n      <th>bedspreads</th>\n      <th>...</th>\n      <th>vanity fair bras</th>\n      <th>vans backpack</th>\n      <th>victoria secret pink shorts</th>\n      <th>victorias secret lace gown</th>\n      <th>videogames ps4</th>\n      <th>volcom short</th>\n      <th>waffle maker</th>\n      <th>wall clocks</th>\n      <th>wall mirrors</th>\n      <th>watch women fossil</th>\n      <th>werewolf costume</th>\n      <th>white dress</th>\n      <th>white jeans</th>\n      <th>white plain dinner set</th>\n      <th>wii</th>\n      <th>wii gamepad</th>\n      <th>wii microphone</th>\n      <th>wine rack</th>\n      <th>wired xbox 360 controller</th>\n      <th>wireless mouse</th>\n      <th>workout clothes for women</th>\n      <th>wreck it ralph</th>\n      <th>yankee candle</th>\n      <th>yankees</th>\n      <th>yellow dress</th>\n      <th>yoga mat</th>\n      <th>yoga pants</th>\n      <th>zippo</th>\n      <th>zippo hand warmer</th>\n      <th>model1_Pred</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td> 2</td>\n      <td>  5</td>\n      <td> 2</td>\n      <td> 1.000005</td>\n      <td>  1</td>\n      <td> 0</td>\n      <td> 0.000005</td>\n      <td> 16</td>\n      <td> 31</td>\n      <td> 1.937500</td>\n      <td>   3</td>\n      <td>  0.187500</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td>...</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> 4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td> 3</td>\n      <td> 12</td>\n      <td> 2</td>\n      <td> 0.666670</td>\n      <td>  1</td>\n      <td> 0</td>\n      <td> 0.000003</td>\n      <td> 21</td>\n      <td> 79</td>\n      <td> 3.761905</td>\n      <td>   3</td>\n      <td>  0.142857</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td>...</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> 4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td> 3</td>\n      <td>  5</td>\n      <td> 3</td>\n      <td> 1.000003</td>\n      <td> 42</td>\n      <td> 3</td>\n      <td> 1.000003</td>\n      <td> 19</td>\n      <td> 30</td>\n      <td> 1.578947</td>\n      <td> 227</td>\n      <td> 11.947368</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td>...</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> False</td>\n      <td> 3</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows \u00d7 274 columns</p>\n</div>"}, "metadata": {}}], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 44, "cell_type": "code", "source": "preds = clf.predict(test)\n# Submission code - final nail in the coffin\n# Create your first submission file\nsubmission = pd.DataFrame({\"id\": idx, \"prediction\": preds})\nsubmission.to_csv(\"C:\\\\axs\\\\work\\\\kaggle\\\\crowdflower\\\\cflower_submit.csv\", index=False)", "outputs": [], "metadata": {"collapsed": false, "trusted": true}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "Python 2", "name": "python2", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "2.7.8", "name": "python", "file_extension": ".py", "pygments_lexer": "ipython2", "codemirror_mode": {"version": 2, "name": "ipython"}}}}