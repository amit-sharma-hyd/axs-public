{"nbformat_minor": 0, "cells": [{"execution_count": null, "cell_type": "code", "source": "\n\"\"\"\nBeating the Benchmark by stacking 3 models\nSearch Results Relevance @ Kaggle\n__author__ : Amit Sharma\n\n\"\"\"\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.svm import SVC\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import decomposition, pipeline, metrics, grid_search\nfrom nltk.stem.porter import *\nimport pandas as pd\nimport numpy as np\nimport re\nimport string\nfrom bs4 import BeautifulSoup\nfrom sklearn.pipeline import Pipeline, FeatureUnion\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVC\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction import text\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.cross_validation import StratifiedShuffleSplit\n\npd.set_option('display.width', 5000) \npd.set_option('display.max_columns', 60) ", "outputs": [], "metadata": {"collapsed": true, "trusted": true}}, {"execution_count": null, "cell_type": "code", "source": "# Reading the trainTest data\ntrainAll = pd.read_csv('C:\\\\axs\\\\work\\\\kaggle\\\\crowdflower\\\\input\\\\train.csv')\n\n# create labels. drop useless columns\nyAll = trainAll.median_relevance.values\ntrainAll = trainAll.drop(['relevance_variance'], axis=1)\n\n#Take a smaller percentage of train\nsss = StratifiedShuffleSplit(yAll, n_iter=3, test_size=0.3)\n\nfor train_index,test_index in sss:\n    trainMaster, testMaster = trainAll.iloc[train_index], trainAll.iloc[test_index]\n    y, testY = yAll[train_index], yAll[test_index]", "outputs": [], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": null, "cell_type": "code", "source": "#stopwords tweak - more overhead\nsw=[]\nstop_words = ['http','www','img','border','0','1','2','3','4','5','6','7','8','9']\nstop_words = text.ENGLISH_STOP_WORDS.union(stop_words)\nfor stw in stop_words:\n    sw.append(\"q\"+stw)\n    sw.append(\"z\"+stw)\nstop_words = text.ENGLISH_STOP_WORDS.union(sw)", "outputs": [], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": null, "cell_type": "code", "source": "# Model 1 - TF IDF based\ntrain = trainMaster.copy()\ntest = testMaster.copy()\n\ntrain = train.drop(['id', 'median_relevance'], axis=1)\ntest = test.drop(['id', 'median_relevance'], axis=1)\n\n# The following 3 functions have been taken from Ben Hamner's github repository\n# https://github.com/benhamner/Metrics\ndef confusion_matrix(rater_a, rater_b, min_rating=None, max_rating=None):\n    \"\"\"\n    Returns the confusion matrix between rater's ratings\n    \"\"\"\n    assert(len(rater_a) == len(rater_b))\n    if min_rating is None:\n        min_rating = min(rater_a + rater_b)\n    if max_rating is None:\n        max_rating = max(rater_a + rater_b)\n    num_ratings = int(max_rating - min_rating + 1)\n    conf_mat = [[0 for i in range(num_ratings)]\n                for j in range(num_ratings)]\n    for a, b in zip(rater_a, rater_b):\n        conf_mat[a - min_rating][b - min_rating] += 1\n    return conf_mat\n\n\ndef histogram(ratings, min_rating=None, max_rating=None):\n    \"\"\"\n    Returns the counts of each type of rating that a rater made\n    \"\"\"\n    if min_rating is None:\n        min_rating = min(ratings)\n    if max_rating is None:\n        max_rating = max(ratings)\n    num_ratings = int(max_rating - min_rating + 1)\n    hist_ratings = [0 for x in range(num_ratings)]\n    for r in ratings:\n        hist_ratings[r - min_rating] += 1\n    return hist_ratings\n\n\ndef quadratic_weighted_kappa(y, y_pred):\n    \"\"\"\n    Calculates the quadratic weighted kappa\n    axquadratic_weighted_kappa calculates the quadratic weighted kappa\n    value, which is a measure of inter-rater agreement between two raters\n    that provide discrete numeric ratings.  Potential values range from -1\n    (representing complete disagreement) to 1 (representing complete\n    agreement).  A kappa value of 0 is expected if all agreement is due to\n    chance.\n    quadratic_weighted_kappa(rater_a, rater_b), where rater_a and rater_b\n    each correspond to a list of integer ratings.  These lists must have the\n    same length.\n    The ratings should be integers, and it is assumed that they contain\n    the complete range of possible ratings.\n    quadratic_weighted_kappa(X, min_rating, max_rating), where min_rating\n    is the minimum possible rating, and max_rating is the maximum possible\n    rating\n    \"\"\"\n    rater_a = y\n    rater_b = y_pred\n    min_rating=None\n    max_rating=None\n    rater_a = np.array(rater_a, dtype=int)\n    rater_b = np.array(rater_b, dtype=int)\n    assert(len(rater_a) == len(rater_b))\n    if min_rating is None:\n        min_rating = min(min(rater_a), min(rater_b))\n    if max_rating is None:\n        max_rating = max(max(rater_a), max(rater_b))\n    conf_mat = confusion_matrix(rater_a, rater_b,\n                                min_rating, max_rating)\n    num_ratings = len(conf_mat)\n    num_scored_items = float(len(rater_a))\n\n    hist_rater_a = histogram(rater_a, min_rating, max_rating)\n    hist_rater_b = histogram(rater_b, min_rating, max_rating)\n\n    numerator = 0.0\n    denominator = 0.0\n\n    for i in range(num_ratings):\n        for j in range(num_ratings):\n            expected_count = (hist_rater_a[i] * hist_rater_b[j]\n                              / num_scored_items)\n            d = pow(i - j, 2.0) / pow(num_ratings - 1, 2.0)\n            numerator += d * conf_mat[i][j] / num_scored_items\n            denominator += d * expected_count / num_scored_items\n\n    return (1.0 - numerator / denominator)\n\n\nif __name__ == '__main__':\n    # do some lambda magic on text columns\n    traindata = list(train.apply(lambda x:'%s %s' % (x['query'],x['product_title']),axis=1))\n    testdata = list(test.apply(lambda x:'%s %s' % (x['query'],x['product_title']),axis=1))\n    \n    # the infamous tfidf vectorizer (Do you remember this one?)\n    tfv = TfidfVectorizer(min_df=3,  max_features=None, \n            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n            ngram_range=(1, 2), use_idf=1,smooth_idf=1,sublinear_tf=1,\n            stop_words = stop_words)\n    \n    # Fit TFIDF\n    tfv.fit(traindata)\n    X =  tfv.transform(traindata) \n    X_test = tfv.transform(testdata)\n    \n    # Initialize SVD\n    svd = TruncatedSVD()\n    \n    # Initialize the standard scaler \n    scl = StandardScaler()\n    \n    # We will use SVM here..\n    svm_model = SVC()\n    \n    # Create the pipeline \n    clf = pipeline.Pipeline([('svd', svd),\n    \t\t\t\t\t\t ('scl', scl),\n                    \t     ('svm', svm_model)])\n    \n    # Create a parameter grid to search for best parameters for everything in the pipeline\n    param_grid = {'svd__n_components' : [400],\n                  'svm__C': [10]}\n    \n    # Kappa Scorer \n    kappa_scorer = metrics.make_scorer(quadratic_weighted_kappa, greater_is_better = True)\n    \n    # Initialize Grid Search Model\n    model = grid_search.GridSearchCV(estimator = clf, param_grid=param_grid, scoring=kappa_scorer,\n                                     verbose=10, n_jobs=1, iid=True, refit=True, cv=2)\n                                     \n    # Fit Grid Search Model\n    model.fit(X, y)\n    print(\"Best score: %0.3f\" % model.best_score_)\n    print(\"Best parameters set:\")\n    best_parameters = model.best_estimator_.get_params()\n    for param_name in sorted(param_grid.keys()):\n    \tprint(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n    \n    # Get best model\n    best_model = model.best_estimator_\n    \n    # Fit model with best parameters optimized for quadratic_weighted_kappa\n    best_model.fit(X,y)\n    model1Preds = best_model.predict(X_test)\n    #model1TrainPreds = best_model.predict(X)\n    print \"Model 1 kappa score: \", metrics.accuracy_score(testY, model1Preds.astype(int))", "outputs": [], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": null, "cell_type": "code", "source": "# Model 2 - Using stemmer\n\ntrain = trainMaster.copy().reset_index()\ntest = testMaster.copy().reset_index()\n\n# array declarations\ns_data = []\ns_labels = []\nt_data = []\nt_labels = []\n\n#remove html, remove non text or numeric, make query and title unique features for counts using prefix (accounted for in stopwords tweak)\nstemmer = PorterStemmer()\n## Stemming functionality\nclass stemmerUtility(object):\n    \"\"\"Stemming functionality\"\"\"\n    @staticmethod\n    def stemPorter(review_text):\n        porter = PorterStemmer()\n        preprocessed_docs = []\n        for doc in review_text:\n            final_doc = []\n            for word in doc:\n                final_doc.append(porter.stem(word))\n                #final_doc.append(wordnet.lemmatize(word)) #note that lemmatize() can also takes part of speech as an argument!\n            preprocessed_docs.append(final_doc)\n        return preprocessed_docs\n\n\nfor i in range(len(train.id)):\n    s=(\" \").join([\"q\"+ z for z in BeautifulSoup(train[\"query\"][i]).get_text(\" \").split(\" \")]) + \\\n        \" \" + (\" \").join([\"z\"+ z for z in BeautifulSoup(train.product_title[i]).get_text(\" \").split(\" \")]) + \\\n        \" \" + BeautifulSoup(str(train.product_description[i])).get_text(\" \")\n    s=re.sub(\"[^a-zA-Z0-9]\",\" \", s)\n    s= (\" \").join([stemmer.stem(z) for z in s.split(\" \")])\n    s_data.append(s)\n    s_labels.append(str(train[\"median_relevance\"][i]))\nfor i in range(len(test.id)):\n    s=(\" \").join([\"q\"+ z for z in BeautifulSoup(test[\"query\"][i]).get_text().split(\" \")]) + \\\n        \" \" + (\" \").join([\"z\"+ z for z in BeautifulSoup(test.product_title[i]).get_text().split(\" \")]) + \\\n        \" \" + BeautifulSoup(str(test.product_description[i])).get_text()\n    s=re.sub(\"[^a-zA-Z0-9]\",\" \", s)\n    s= (\" \").join([stemmer.stem(z) for z in s.split(\" \")])\n    t_data.append(s)\n#create sklearn pipeline, fit all, and predit test data\nclf = Pipeline([('v',TfidfVectorizer(min_df=5, max_df=500, max_features=None, strip_accents='unicode', \n                                     analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(1, 2), use_idf=True,\n                                     smooth_idf=True, sublinear_tf=True, stop_words = stop_words)), \n('svd', TruncatedSVD(n_components=200, algorithm='randomized', n_iter=5, random_state=None, tol=0.0)), \n('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), \n('svm', SVC(C=10.0, kernel='rbf', degree=3, gamma=0.0, coef0=0.0, shrinking=True, probability=False, \n            tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, random_state=None))])\nclf.fit(s_data, s_labels)\nmodel2Preds = clf.predict(t_data).astype(int)\n#model2TrainPreds = clf.predict(s_data)\nprint \"Model 2 kappa score: \", metrics.accuracy_score(testY, model2Preds)", "outputs": [], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": null, "cell_type": "code", "source": "from sklearn.ensemble import GradientBoostingClassifier\n\n# Model 2 - Using stemmer\n\ntrain = trainMaster.copy()\ntest = testMaster.copy()\n\ntrain = train.drop(['id', 'median_relevance'], axis=1)\ntest = test.drop(['id', 'median_relevance'], axis=1)\n\n# Model 3 - Based on features\ndef query_title_common(row):\n    return (set(row['query'].split()) & set(row['product_title'].split()))\n\ndef query_desc_common(row):\n    return (set(row['query'].split()) & set(row['pdesc'].split()))\n\n\ndef getTitleFeatures(df):\n    df['query'] = df['query'].astype('str')\n    df['product_title'] = df['product_title'].astype('str')\n    # Lowercase everything\n    df['query'] = df['query'].str.lower()\n    df['product_title'] = df['product_title'].str.lower()\n    df['query_len'] = df['query'].str.len()\n    df['ptitle_len'] = df['product_title'].str.len()\n\n    df['query_nwords'] = df['query'].str.split().str.len()\n\n    df['query_title'] = df.apply(query_title_common,axis=1)\n    df['query_title_nwords'] = df['query_title'].str.len()\n    df['title_nwords'] = df['product_title'].str.split().str.len()\n    df['query_title_match'] = df['query_title_nwords']/df['query_nwords']\n    \n    #df = df[['query_nwords', 'title_nwords', 'query_title_nwords', 'query_title_match', 'query_len', 'ptitle_len']]\n    df = df.drop(['query_title'],axis=1)\n        \n    return (df)\n\ndef getDescFeatures(df):\n    df['product_description'] = df['product_description'].astype('str')\n    df['product_description'] = df['product_description'].str.lower()\n    df['pdesc'] = map(lambda x: BeautifulSoup(''.join(x)).text, df['product_description'])\n    df['query_nwords'] = df['query'].str.split().str.len()\n\n    df['query_desc'] = df.apply(query_desc_common,axis=1)\n    df['query_desc_nwords'] = df['query_desc'].str.len()\n    df['desc_nwords'] = df['pdesc'].str.split().str.len()\n    df['query_desc_match'] = df['query_desc_nwords']/df['query_nwords']\n\n    df['query'] = df['query'].astype(str)\n\n    df['query_len'] = df['query'].str.len()\n    df['pdesc_len'] = df['pdesc'].str.len()\n    df['query_desc_match'] = (df['query_desc_nwords']+0.00001)/df['query_nwords']\n    df['pdesc_size_over_query'] = df['pdesc_len']/df['query_len']\n    \n    df = df.drop(['pdesc', 'query_desc', ], axis=1)\n\n    return (df)\n\ndef addFeatures(df):\n    df = getTitleFeatures(df)\n    df = getDescFeatures(df)\n \n    # Create dummy columns for categorical variable as scikit does not understand factors\n    #dummyDF = pd.get_dummies(df['query'])\n    #dummyDF= dummyDF.astype(bool)\n    #df = pd.concat([df,dummyDF],axis=1)\n    \n    df = df.drop(['query', 'product_title', 'product_description'], axis=1)\n\n    return (df)\n\ntrain = addFeatures(train)\ntest = addFeatures(test)\n\nclf = GradientBoostingClassifier(n_estimators=25, learning_rate=0.7, max_depth=2, random_state=0).fit(train, y)\n\nmodel3Preds = clf.predict(test)\n#model3TrainPreds = clf.predict(train)\nprint \"Model 3 kappa score: \", metrics.accuracy_score(testY, model3Preds.astype(int))", "outputs": [], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 192, "cell_type": "code", "source": "# Model 4\n\ntrain = trainMaster.copy().reset_index()\ntest = testMaster.copy().reset_index()\n\n\n# array declarations\nsw=[]\ns_data = []\ns_labels = []\nt_data = []\nt_labels = []\nstemmer = PorterStemmer()\n#stopwords tweak - more overhead\nstop_words = ['http','www','img','border','color','style','padding','table','font','thi','inch','ha','width','height',\n'0','1','2','3','4','5','6','7','8','9']\n#stop_words = text.ENGLISH_STOP_WORDS.union(stop_words)\n\n#stop_words = ['http','www','img','border','0','1','2','3','4','5','6','7','8','9']\nstop_words = text.ENGLISH_STOP_WORDS.union(stop_words)\n\npunct = string.punctuation\npunct_re = re.compile('[{}]'.format(re.escape(punct)))\n\n#remove html, remove non text or numeric, make query and title unique features for counts using prefix (accounted for in stopwords tweak)\nstemmer = PorterStemmer()\n## Stemming functionality\nclass stemmerUtility(object):\n    \"\"\"Stemming functionality\"\"\"\n    @staticmethod\n    def stemPorter(review_text):\n        porter = PorterStemmer()\n        preprocessed_docs = []\n        for doc in review_text:\n            final_doc = []\n            for word in doc:\n                final_doc.append(porter.stem(word))\n                #final_doc.append(wordnet.lemmatize(word)) #note that lemmatize() can also takes part of speech as an argument!\n            preprocessed_docs.append(final_doc)\n        return preprocessed_docs\n    \ndef preprocess(x):\n    x=x.lower()\n    x=re.sub(\"[^a-zA-Z0-9]\",\" \", x)\n    x=punct_re.sub(' ', x)\n    new_x = []\n    for token in x.split(' '):\n        new_x.append(stemmer.stem(token))\n    return ' '.join(new_x)\n# Fit TFIDF\nimport scipy.sparse\ndef vectorize(train, tfv_query=None):\n    query_data = list(train['query'].apply(preprocess))\n    title_data = list(train['product_title'].apply(preprocess))\n    if tfv_query is None:\n        tfv_query = TfidfVectorizer(min_df=3,  max_features=None,   \n                strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n                ngram_range=(1, 5), use_idf=1,smooth_idf=1,sublinear_tf=1,\n                stop_words =stop_words)\n\n        full_data = query_data + title_data\n        tfv_query.fit(full_data)\n\n    return scipy.sparse.hstack([tfv_query.transform(query_data), tfv_query.transform(title_data)]), tfv_query\n\nX, tfv_query = vectorize(train)\nX_test, _ = vectorize(test, tfv_query)\n\n# Add title features\ntrainTitleFeatures = getTitleFeatures(train.copy())\ntrainTitleFeatures = trainTitleFeatures.drop(['index','id', 'query', 'median_relevance', 'product_title','product_description'], axis=1)\ntestTitleFeatures = getTitleFeatures(test.copy())\ntestTitleFeatures = testTitleFeatures.drop(['index','id', 'query', 'median_relevance', 'product_title','product_description'], axis=1)\n\ntrainDescFeatures = getDescFeatures(train.copy())\ntrainDescFeatures = trainDescFeatures.drop(['index','id', 'query', 'median_relevance', 'product_title','product_description'], axis=1)\ntestDescFeatures = getDescFeatures(test.copy())\ntestDescFeatures = testDescFeatures.drop(['index','id', 'query', 'median_relevance', 'product_title','product_description'], axis=1)\n\n\n# Initialize SVD\nsvd = TruncatedSVD(n_components=400)\nfrom sklearn.metrics.pairwise import linear_kernel\nclass FeatureInserter():\n\n    def __init__(self):\n        pass\n\n    def transform(self, X, y=None):\n        distances = []\n        quasi_jaccard = []\n        #print(len(distances), X.shape)\n        \n        titleFeatures = []\n        descFeatures = []\n        \n        if X.shape[0] == trainTitleFeatures.shape[0]:\n            titleFeatures = trainTitleFeatures\n            descFeatures = trainDescFeatures\n        else:\n            titleFeatures = testTitleFeatures\n            descFeatures = testDescFeatures\n\n        for row in X.tocsr():\n            row=row.toarray().ravel()\n            #print row[:row.shape[0]/2], row[row.shape[0]/2:]\n            cos_distance = linear_kernel(row[:row.shape[0]/2], row[row.shape[0]/2:])\n            distances.append(cos_distance[0])\n            intersect = row[:row.shape[0]/2].dot(row[row.shape[0]/2:])\n            union = (row[:row.shape[0]/2]+row[row.shape[0]/2:]).dot((row[:row.shape[0]/2]+row[row.shape[0]/2:]))\n            quasi_jaccard.append(1.0*intersect/union)\n\n        #print(len(distances), X.shape)\n        #print(distances[:10])\n\n        #X = scipy.sparse.hstack([X, distances])\n        #ret= np.matrix([x for x in zip(distances, quasi_jaccard)])\n        ret = pd.DataFrame([x for x in zip(distances, quasi_jaccard)])\n        ret = pd.concat([ret, titleFeatures], axis=1)\n        #ret = pd.concat([ret, descFeatures], axis=1)\n        \n        return ret\n    \n    def fit(self, X,y):\n        return self\n\n\n    def fit_transform(self, X, y, **fit_params):\n        self.fit(X,y)\n        return self.transform(X)\n\n# Initialize the standard scaler \nscl = StandardScaler()\n\n# We will use SVM here..\nsvm_model = SVC(C=10.)\n\n# Create the pipeline \nmodel = pipeline.Pipeline([('UnionInput', FeatureUnion([('svd', svd), ('dense_features', FeatureInserter())])),\n                         ('scl', scl),\n                         ('svm', svm_model)])\n# Fit Model\nmodel.fit(X, y)\n\npreds = model.predict(X_test)\n\nfor i in range(len(train.id)):\n    s=(\" \").join([\"q\"+ z for z in BeautifulSoup(train[\"query\"][i]).get_text(\" \").split(\" \")]) + \\\n        \" \" + (\" \").join([\"z\"+ z for z in BeautifulSoup(train.product_title[i]).get_text(\" \").split(\" \")]) + \\\n        \" \" + BeautifulSoup(str(train.product_description[i])).get_text(\" \")\n    s=re.sub(\"[^a-zA-Z0-9]\",\" \", s)\n    s= (\" \").join([stemmer.stem(z) for z in s.split(\" \")])\n    s=s.lower()\n    s=s.replace(\"nan\", \"\")\n    s_data.append(s)\n    s_labels.append(str(train[\"median_relevance\"][i]))\nfor i in range(len(test.id)):\n    s=(\" \").join([\"q\"+ z for z in BeautifulSoup(test[\"query\"][i]).get_text().split(\" \")]) + \\\n        \" \" + (\" \").join([\"z\"+ z for z in BeautifulSoup(test.product_title[i]).get_text().split(\" \")]) + \\\n        \" \" + BeautifulSoup(str(test.product_description[i])).get_text()\n    s=re.sub(\"[^a-zA-Z0-9]\",\" \", s)\n    s=s.lower()\n    s=s.replace(\"nan\", \"\")\n    s= (\" \").join([stemmer.stem(z) for z in s.split(\" \")])\n    t_data.append(s)\n#create sklearn pipeline, fit all, and predit test data\nclf = Pipeline([('v',TfidfVectorizer(min_df=5, max_df=500, max_features=None, strip_accents='unicode', \\\n                                    analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(1, 5), use_idf=True, \\\n                                     smooth_idf=True, sublinear_tf=True, stop_words = stop_words)), \n('UnionInput', FeatureUnion([('svd', TruncatedSVD(n_components=300, algorithm='randomized', n_iter=5, random_state=None, tol=0.0)), ('dense_features', FeatureInserter())])),\n#('svd', TruncatedSVD(n_components=300, algorithm='randomized', n_iter=5, random_state=None, tol=0.0)), \n('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), \n('svm', SVC(C=10.0, kernel='rbf', degree=3, gamma=0.0, coef0=0.0, shrinking=True, probability=False, tol=0.001, \\\n            cache_size=200, class_weight=None, verbose=False, max_iter=-1, random_state=None))])\nclf.fit(s_data, s_labels)\nt_labels = clf.predict(t_data)\n\nimport math\nmodel4Preds = []\nfor i in range(len(preds)):\n    x =math.sqrt((int(t_labels[i]))*preds[i])\n    x = round(x)\n    model4Preds.append(int(x))\nprint \"Model 4 kappa score: \", metrics.accuracy_score(testY, model4Preds)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Model 4 kappa score:  0.64501312336\n"}], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 194, "cell_type": "code", "source": "metrics.accuracy_score(testY, t_labels.astype(int))", "outputs": [{"execution_count": 194, "output_type": "execute_result", "data": {"text/plain": "0.65485564304461941"}, "metadata": {}}], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": null, "cell_type": "code", "source": "#Eval the results on the train set\nprint \"Model 1 kappa score: \", metrics.accuracy_score(testY, model1Preds)\nprint \"Model 2 kappa score: \", metrics.accuracy_score(testY, model2Preds)\nprint \"Model 3 kappa score: \", metrics.accuracy_score(testY, model3Preds)\nprint \"Model 4 kappa score: \", metrics.accuracy_score(testY, model4Preds)", "outputs": [], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": null, "cell_type": "code", "source": "model1Preds.shape, model2Preds.shape\nfrom scipy.stats.stats import pearsonr   \nprint \"Correlation Coeff 1-2: \", pearsonr(model1Preds, model2Preds)\nprint \"Correlation Coeff 1-3: \", pearsonr(model1Preds, model3Preds)\nprint \"Correlation Coeff 1-4: \", pearsonr(model1Preds, model4Preds)\nprint \"Correlation Coeff 2-3: \", pearsonr(model2Preds, model3Preds)\nprint \"Correlation Coeff 2-4: \", pearsonr(model2Preds, model4Preds)\nprint \"Correlation Coeff 3-4: \", pearsonr(model3Preds, model4Preds)", "outputs": [], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": null, "cell_type": "code", "source": "import math\np12 = []\np13 = []\np14 = []\np23 = []\np24 = []\np34 = []\n\nfor i in range(len(testY)):\n    x = math.sqrt(int(model1Preds[i]) * int(model2Preds[i]) )\n    x = math.floor(x)\n    p12.append(int(x))\n    x = math.sqrt(int(model1Preds[i]) * int(model3Preds[i]) )\n    x = math.floor(x)\n    p13.append(int(x))\n    x = math.sqrt(int(model1Preds[i]) * int(model4Preds[i]) )\n    x = math.floor(x)\n    p14.append(int(x))\n    x = math.sqrt(int(model2Preds[i]) * int(model3Preds[i]) )\n    x = math.floor(x)\n    p23.append(int(x))\n    x = math.sqrt(int(model2Preds[i]) * int(model4Preds[i]) )\n    x = math.floor(x)\n    p24.append(int(x))\n    x = math.sqrt(int(model3Preds[i]) * int(model4Preds[i]) )\n    x = math.floor(x)\n    p34.append(int(x))\n    \n    \nprint \"Blended kappa score p12: \", metrics.accuracy_score(testY, p12)    \nprint \"Blended kappa score p13: \", metrics.accuracy_score(testY, p13)    \nprint \"Blended kappa score p14: \", metrics.accuracy_score(testY, p14)    \nprint \"Blended kappa score p23: \", metrics.accuracy_score(testY, p23)    \nprint \"Blended kappa score p24: \", metrics.accuracy_score(testY, p24)    \nprint \"Blended kappa score p34: \", metrics.accuracy_score(testY, p34)    ", "outputs": [], "metadata": {"collapsed": false, "trusted": true}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "Python 2", "name": "python2", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "2.7.8", "name": "python", "file_extension": ".py", "pygments_lexer": "ipython2", "codemirror_mode": {"version": 2, "name": "ipython"}}}}