{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.kaggle.com/c/talkingdata-mobile-user-demographics/data\">Talking Data on Kaggle</a>\n",
    "<img src=\"domain.png\" width=\"600\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import cross_validation, ensemble, preprocessing, metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import log_loss, confusion_matrix\n",
    "submission = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def map_column(table, f):\n",
    "    labels = sorted(table[f].unique())\n",
    "    mappings = dict()\n",
    "    for i in range(len(labels)):\n",
    "        mappings[labels[i]] = i\n",
    "    table = table.replace({f: mappings})\n",
    "    return table\n",
    "\n",
    "def handleTimestamp(df):\n",
    "    dateTimeStr = df.timestamp\n",
    "    dateTimeStr = dateTimeStr.fillna(\"2016-05-03 05:04:58\")\n",
    "    datetime = pd.to_datetime(dateTimeStr)\n",
    "    # create some new features\n",
    "    df['year'] = datetime.dt.year.astype(int)\n",
    "    df['month'] = datetime.dt.month.astype(int)\n",
    "    df['dayofweek'] = datetime.dt.dayofweek.astype(int)\n",
    "    df['day'] = datetime.dt.day.astype(int)\n",
    "    df['hour'] = datetime.dt.hour.astype(int)\n",
    "    df['minute'] = datetime.dt.minute.astype(int)\n",
    "    \n",
    "    df = df.drop(['timestamp'], axis=1)\n",
    "    return df\n",
    "\n",
    "# Plots the frequency count, figSize=(5,4)\n",
    "def barPlot(df, col=None, N=None, figSize=None):\n",
    "    if N is None:\n",
    "        N = df[col].unique().shape[0]\n",
    "\n",
    "    freqs = df[col].value_counts()[:N]\n",
    "    index = np.arange(0,N)\n",
    "    width=0.8\n",
    "    fig, ax = plt.subplots(figsize=figSize)\n",
    "    rects1 = ax.bar(index, freqs, width, color='red', alpha=0.5)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(col)\n",
    "    plt.xticks(index + width/2., freqs.index)\n",
    "    plt.xticks(rotation=60)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read Labels...\n",
      "Processing:  shop\n",
      "Processing:  fashion\n",
      "Processing:  photo\n",
      "Processing:  relative\n",
      "Processing:  video\n",
      "Processing:  church\n",
      "Processing:  education\n",
      "Processing:  investment\n",
      "Processing:  risk\n",
      "Processing:  wealth\n",
      "Processing:  service\n",
      "Processing:  readers\n",
      "Processing:  travel\n",
      "Processing:  music\n",
      "Processing:  income\n",
      "Processing:  health\n",
      "Processing:  finance\n",
      "Processing:  game\n",
      "Processing:  p2p\n",
      "Processing:  baby\n",
      "Processing:  news\n",
      "Processing:  bank\n",
      "Processing:  pursue\n",
      "Processing:  science\n",
      "Processing:  industry\n",
      "Processing:  im\n",
      "Processing:  property\n",
      "Processing:  medical\n",
      "Merging with events...\n",
      "App Events DF loaded...\n",
      "Read events...\n",
      "Aggregating cat cols...\n",
      "Writing to file...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print \"Read Labels...\"\n",
    "# Merge the labels\n",
    "appLabelsDF = pd.read_csv(\"data/app_labels.csv\", low_memory=False, \n",
    "                  dtype= {'app_id': np.str, 'label_id': np.str, \n",
    "                          'is_installed': np.int, 'is_active':np.int})\n",
    "lblCatsDF = pd.read_csv(\"data/label_categories.csv\", low_memory=False, \n",
    "                  dtype= {'label_id': np.str})\n",
    "lblCatsDF.category.fillna('unknown')\n",
    "lblCatsDF.category = lblCatsDF.category.map(lambda x: str(x).lower())\n",
    "\n",
    "appLabelsDF = appLabelsDF.merge(lblCatsDF, how=\"left\", on=\"label_id\")      \n",
    "appLabelsDF = appLabelsDF.drop('label_id', axis=1)\n",
    "\n",
    "# topCatCols = ['industry tag', 'property industry 2.0', 'property industry 1.0',\n",
    "# 'custom label', 'services 1', 'and the church',\n",
    "# 'internet banking', 'finance', 'p2p', 'low risk', 'p2p net loan',\n",
    "# 'liquid medium', 'relatives 1', 'pay', 'high risk', '1 free',\n",
    "# 'wealth management', 'personal effectiveness 1', 'im',\n",
    "# 'higher income', 'financial', 'mobile bank', 'low income',\n",
    "# 'debit and credit', 'online malls', 'low liquidity', 'video',\n",
    "# 'pursue', 'financial services', 'low profitability',\n",
    "# 'moderate profitability', 'high flow', 'fashion',\n",
    "# 'third party payment', 'bank financing', 'direct banking',\n",
    "# 'total cost 1', 'direct bank', 'science and technology', 'cozy 1',\n",
    "# 'tencent', 'music', 'fixed income', 'smart shopping 1',\n",
    "# 'securities', 'consumer finance', 'ds_p2p net loan', 'imf',\n",
    "# 'air travel']\n",
    "\n",
    "# catCols = ['Cat_'+x for x in topCatCols[:40]]\n",
    "\n",
    "# print('Dummifying category labels...')\n",
    "# appLabelsDF = pd.get_dummies(appLabelsDF, prefix='Cat', columns=['category'] )\n",
    "# appLabelsDF = appLabelsDF[['app_id'] + catCols]\n",
    "# appLabelsDF[catCols] = appLabelsDF[catCols].astype(int)\n",
    "\n",
    "# catCols = [x for x in appLabelsDF.columns if \"cat_\" in x]\n",
    "catCols = {'game':['game', 'gaming'], \n",
    "           'industry':['industry'], \n",
    "           'property':['property'],\n",
    "           'service': ['service'], \n",
    "           'church':['church'], \n",
    "           'p2p':['p2p'], \n",
    "           'finance':['financ', 'financial', 'debit', 'credit', 'account', 'business'],\n",
    "           'investment': ['fund', 'stock', 'loan', 'securities', 'insurance', \n",
    "                          'profit', 'risk', 'liquidity', 'futures'], \n",
    "           'im':['im'], \n",
    "           'relative':['relative'], \n",
    "           'news':['news'],\n",
    "           'bank':['bank'], \n",
    "           'pursue':['pursue'],  \n",
    "           'risk':['risk'], \n",
    "           'income':['income', 'pay'], \n",
    "           'fashion':['fashion', 'trend', 'cool' ], \n",
    "           'shop':['shop', 'price', 'groupon', 'free', 'mall'], \n",
    "           'science':['science', 'techno'], \n",
    "           'video':['video', 'film', 'movie', 'show'], \n",
    "           'music':['music', 'radio'], \n",
    "           'wealth':['wealth'], \n",
    "           'travel':['travel', 'tour', 'taxi', 'map', 'car', 'navigat', 'rail', \n",
    "                     'flight', 'bus', 'hotel', 'transport'],\n",
    "           'education': ['educat', 'literature', 'class', 'exam', 'college' ],\n",
    "           'health': ['health', 'sports', 'gym', 'exercise', 'vitality'],\n",
    "           'photo':['photo', 'picture', ],\n",
    "           'readers': ['read', 'blog', 'novel', 'book', 'comic'],\n",
    "           'baby': ['baby', 'pregnan'],\n",
    "           'medical':['medical']}\n",
    "\n",
    "for catCol in catCols.keys():\n",
    "    print \"Processing: \", catCol\n",
    "    for catKey in catCols[catCol]:\n",
    "        appLabelsDF[catCol] = [1 if catKey in x else None for x in appLabelsDF.category]\n",
    "\n",
    "appLabelsDF = appLabelsDF.groupby('app_id')[catCols.keys()].sum()\n",
    "appLabelsDF.reset_index(inplace=True)\n",
    "\n",
    "print('Merging with events...')\n",
    "appEventsDF = pd.read_csv(\"data/app_events.csv\", low_memory=False, \n",
    "                  dtype= {'app_id': np.str, 'event_id': np.str})\n",
    "#appEventsDF = appEventsDF[appEventsDF.is_active==1]\n",
    "appEventsDF = appEventsDF.merge(appLabelsDF, how=\"left\", on=\"app_id\")\n",
    "appEventsDF = appEventsDF.groupby('event_id')[catCols.keys()].sum()\n",
    "appEventsDF.reset_index(inplace=True)\n",
    "print \"App Events DF loaded...\"\n",
    "\n",
    "# Events\n",
    "print('Read events...')\n",
    "events = pd.read_csv(\"./data/events.csv\", dtype={'device_id': np.str, 'event_id': np.str})\n",
    "events = pd.merge(events, appEventsDF, how=\"left\", on=\"event_id\", left_index=True)\n",
    "\n",
    "print \"Aggregating cat cols...\"\n",
    "events_acc = events.groupby('device_id')[catCols.keys()].sum()\n",
    "events_acc.reset_index(inplace=True)\n",
    "\n",
    "events.longitude = [int(lo) if lo > 0 else None for lo in events.longitude]    \n",
    "events.latitude = [int(lo) if lo > 0 else None for lo in events.latitude]\n",
    "events.longitude = np.digitize(events.longitude, np.linspace(0,max(events.longitude),20))\n",
    "events.latitude = np.digitize(events.latitude, np.linspace(0,max(events.latitude),20))    \n",
    "\n",
    "events = handleTimestamp(events)\n",
    "\n",
    "events_llt = events.groupby('device_id')[['longitude', 'latitude', 'dayofweek', 'hour']].median()\n",
    "events_llt.reset_index(inplace=True)\n",
    "\n",
    "events_acc = pd.merge(events_acc, events_llt, how=\"left\", on=\"device_id\", left_index=True)\n",
    "print('Writing to file...')\n",
    "events_acc.to_csv(\"eventApps.csv\", index=False)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read brands...\n",
      "Read train...\n",
      "Read test...\n",
      "('Length of train: ', 74645)\n",
      "('Length of test: ', 112071)\n",
      "Features [34]: ['baby', 'bank', 'church', 'dayofweek', 'device_model', 'education', 'fashion', 'finance', 'game', 'health', 'hour', 'im', 'income', 'industry', 'investment', 'latitude', 'longitude', 'medical', 'music', 'news', 'p2p', 'phone_brand', 'photo', 'property', 'pursue', 'readers', 'relative', 'risk', 'science', 'service', 'shop', 'travel', 'video', 'wealth']\n",
      "XGBoost params. ETA: 0.1, MAX_DEPTH: 5, SUBSAMPLE: 0.7, COLSAMPLE_BY_TREE: 0.7\n",
      "('Length train:', 52251)\n",
      "('Length valid:', 22394)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until eval error hasn't decreased in 50 rounds.\n",
      "[0]\ttrain-mlogloss:2.470716\teval-mlogloss:2.473666\n",
      "[1]\ttrain-mlogloss:2.457588\teval-mlogloss:2.462728\n",
      "[2]\ttrain-mlogloss:2.445729\teval-mlogloss:2.453182\n",
      "[3]\ttrain-mlogloss:2.434854\teval-mlogloss:2.444403\n",
      "[4]\ttrain-mlogloss:2.425210\teval-mlogloss:2.436622\n",
      "[5]\ttrain-mlogloss:2.416497\teval-mlogloss:2.430084\n",
      "[6]\ttrain-mlogloss:2.407847\teval-mlogloss:2.423815\n",
      "[7]\ttrain-mlogloss:2.400530\teval-mlogloss:2.418463\n",
      "[8]\ttrain-mlogloss:2.393397\teval-mlogloss:2.413527\n",
      "[9]\ttrain-mlogloss:2.386638\teval-mlogloss:2.408726\n",
      "[10]\ttrain-mlogloss:2.380856\teval-mlogloss:2.404810\n",
      "[11]\ttrain-mlogloss:2.375119\teval-mlogloss:2.400925\n",
      "[12]\ttrain-mlogloss:2.369834\teval-mlogloss:2.397434\n",
      "[13]\ttrain-mlogloss:2.364846\teval-mlogloss:2.394450\n",
      "[14]\ttrain-mlogloss:2.360113\teval-mlogloss:2.391608\n",
      "[15]\ttrain-mlogloss:2.355510\teval-mlogloss:2.388810\n",
      "[16]\ttrain-mlogloss:2.351429\teval-mlogloss:2.386533\n",
      "[17]\ttrain-mlogloss:2.347353\teval-mlogloss:2.384270\n",
      "[18]\ttrain-mlogloss:2.343543\teval-mlogloss:2.382242\n",
      "[19]\ttrain-mlogloss:2.339774\teval-mlogloss:2.380141\n",
      "[20]\ttrain-mlogloss:2.336485\teval-mlogloss:2.378526\n",
      "[21]\ttrain-mlogloss:2.333231\teval-mlogloss:2.376727\n",
      "[22]\ttrain-mlogloss:2.330128\teval-mlogloss:2.375126\n",
      "[23]\ttrain-mlogloss:2.326989\teval-mlogloss:2.373752\n",
      "[24]\ttrain-mlogloss:2.324226\teval-mlogloss:2.372496\n",
      "[25]\ttrain-mlogloss:2.321548\teval-mlogloss:2.371169\n",
      "[26]\ttrain-mlogloss:2.319039\teval-mlogloss:2.370159\n",
      "[27]\ttrain-mlogloss:2.316629\teval-mlogloss:2.369242\n",
      "[28]\ttrain-mlogloss:2.314178\teval-mlogloss:2.368364\n",
      "[29]\ttrain-mlogloss:2.311706\teval-mlogloss:2.367562\n",
      "[30]\ttrain-mlogloss:2.309376\teval-mlogloss:2.366732\n",
      "[31]\ttrain-mlogloss:2.307199\teval-mlogloss:2.365898\n",
      "[32]\ttrain-mlogloss:2.304989\teval-mlogloss:2.365202\n",
      "[33]\ttrain-mlogloss:2.302923\teval-mlogloss:2.364584\n",
      "[34]\ttrain-mlogloss:2.300892\teval-mlogloss:2.363901\n",
      "[35]\ttrain-mlogloss:2.298996\teval-mlogloss:2.363401\n",
      "[36]\ttrain-mlogloss:2.297014\teval-mlogloss:2.362893\n",
      "[37]\ttrain-mlogloss:2.295301\teval-mlogloss:2.362416\n",
      "[38]\ttrain-mlogloss:2.293595\teval-mlogloss:2.362003\n",
      "[39]\ttrain-mlogloss:2.291653\teval-mlogloss:2.361684\n",
      "[40]\ttrain-mlogloss:2.289872\teval-mlogloss:2.361251\n",
      "[41]\ttrain-mlogloss:2.288186\teval-mlogloss:2.360941\n",
      "[42]\ttrain-mlogloss:2.286451\teval-mlogloss:2.360615\n",
      "[43]\ttrain-mlogloss:2.284688\teval-mlogloss:2.360350\n",
      "[44]\ttrain-mlogloss:2.283005\teval-mlogloss:2.360043\n",
      "[45]\ttrain-mlogloss:2.281427\teval-mlogloss:2.359626\n",
      "[46]\ttrain-mlogloss:2.279914\teval-mlogloss:2.359436\n",
      "[47]\ttrain-mlogloss:2.278064\teval-mlogloss:2.359078\n",
      "[48]\ttrain-mlogloss:2.276379\teval-mlogloss:2.358800\n",
      "[49]\ttrain-mlogloss:2.274832\teval-mlogloss:2.358474\n",
      "[50]\ttrain-mlogloss:2.273271\teval-mlogloss:2.358259\n",
      "[51]\ttrain-mlogloss:2.271674\teval-mlogloss:2.358078\n",
      "[52]\ttrain-mlogloss:2.270413\teval-mlogloss:2.357908\n",
      "[53]\ttrain-mlogloss:2.269063\teval-mlogloss:2.357691\n",
      "[54]\ttrain-mlogloss:2.267664\teval-mlogloss:2.357392\n",
      "[55]\ttrain-mlogloss:2.266115\teval-mlogloss:2.357143\n",
      "[56]\ttrain-mlogloss:2.264701\teval-mlogloss:2.356846\n",
      "[57]\ttrain-mlogloss:2.263520\teval-mlogloss:2.356738\n",
      "[58]\ttrain-mlogloss:2.262189\teval-mlogloss:2.356611\n",
      "[59]\ttrain-mlogloss:2.260875\teval-mlogloss:2.356368\n",
      "[60]\ttrain-mlogloss:2.259335\teval-mlogloss:2.356224\n",
      "[61]\ttrain-mlogloss:2.257992\teval-mlogloss:2.355950\n",
      "[62]\ttrain-mlogloss:2.256793\teval-mlogloss:2.355826\n",
      "[63]\ttrain-mlogloss:2.255582\teval-mlogloss:2.355649\n",
      "[64]\ttrain-mlogloss:2.254122\teval-mlogloss:2.355358\n",
      "[65]\ttrain-mlogloss:2.252736\teval-mlogloss:2.355269\n",
      "[66]\ttrain-mlogloss:2.251483\teval-mlogloss:2.355100\n",
      "[67]\ttrain-mlogloss:2.250608\teval-mlogloss:2.354964\n",
      "[68]\ttrain-mlogloss:2.249489\teval-mlogloss:2.354901\n",
      "[69]\ttrain-mlogloss:2.248178\teval-mlogloss:2.354598\n",
      "[70]\ttrain-mlogloss:2.247277\teval-mlogloss:2.354537\n",
      "[71]\ttrain-mlogloss:2.246127\teval-mlogloss:2.354273\n",
      "[72]\ttrain-mlogloss:2.245019\teval-mlogloss:2.354191\n",
      "[73]\ttrain-mlogloss:2.243847\teval-mlogloss:2.354105\n",
      "[74]\ttrain-mlogloss:2.242648\teval-mlogloss:2.354107\n",
      "[75]\ttrain-mlogloss:2.241445\teval-mlogloss:2.353971\n",
      "[76]\ttrain-mlogloss:2.240243\teval-mlogloss:2.353887\n",
      "[77]\ttrain-mlogloss:2.238973\teval-mlogloss:2.353855\n",
      "[78]\ttrain-mlogloss:2.237630\teval-mlogloss:2.353648\n",
      "[79]\ttrain-mlogloss:2.236402\teval-mlogloss:2.353494\n",
      "[80]\ttrain-mlogloss:2.235193\teval-mlogloss:2.353391\n",
      "[81]\ttrain-mlogloss:2.233992\teval-mlogloss:2.353298\n",
      "[82]\ttrain-mlogloss:2.232644\teval-mlogloss:2.353266\n",
      "[83]\ttrain-mlogloss:2.231416\teval-mlogloss:2.353174\n",
      "[84]\ttrain-mlogloss:2.230278\teval-mlogloss:2.353149\n",
      "[85]\ttrain-mlogloss:2.229036\teval-mlogloss:2.353001\n",
      "[86]\ttrain-mlogloss:2.227871\teval-mlogloss:2.352889\n",
      "[87]\ttrain-mlogloss:2.226707\teval-mlogloss:2.352877\n",
      "[88]\ttrain-mlogloss:2.225507\teval-mlogloss:2.352835\n",
      "[89]\ttrain-mlogloss:2.224257\teval-mlogloss:2.352772\n",
      "[90]\ttrain-mlogloss:2.223014\teval-mlogloss:2.352799\n",
      "[91]\ttrain-mlogloss:2.222066\teval-mlogloss:2.352784\n",
      "[92]\ttrain-mlogloss:2.221104\teval-mlogloss:2.352665\n",
      "[93]\ttrain-mlogloss:2.220011\teval-mlogloss:2.352519\n",
      "[94]\ttrain-mlogloss:2.218845\teval-mlogloss:2.352485\n",
      "[95]\ttrain-mlogloss:2.217993\teval-mlogloss:2.352460\n",
      "[96]\ttrain-mlogloss:2.216862\teval-mlogloss:2.352222\n",
      "[97]\ttrain-mlogloss:2.215855\teval-mlogloss:2.352234\n",
      "[98]\ttrain-mlogloss:2.214666\teval-mlogloss:2.352204\n",
      "[99]\ttrain-mlogloss:2.213724\teval-mlogloss:2.352247\n",
      "[100]\ttrain-mlogloss:2.212777\teval-mlogloss:2.352245\n",
      "[101]\ttrain-mlogloss:2.211525\teval-mlogloss:2.352188\n",
      "[102]\ttrain-mlogloss:2.210529\teval-mlogloss:2.352093\n",
      "[103]\ttrain-mlogloss:2.209374\teval-mlogloss:2.352095\n",
      "[104]\ttrain-mlogloss:2.208431\teval-mlogloss:2.352033\n",
      "[105]\ttrain-mlogloss:2.207300\teval-mlogloss:2.351908\n",
      "[106]\ttrain-mlogloss:2.206193\teval-mlogloss:2.351936\n",
      "[107]\ttrain-mlogloss:2.205389\teval-mlogloss:2.351877\n",
      "[108]\ttrain-mlogloss:2.204501\teval-mlogloss:2.351907\n",
      "[109]\ttrain-mlogloss:2.203522\teval-mlogloss:2.351790\n",
      "[110]\ttrain-mlogloss:2.202441\teval-mlogloss:2.351729\n",
      "[111]\ttrain-mlogloss:2.201317\teval-mlogloss:2.351722\n",
      "[112]\ttrain-mlogloss:2.200342\teval-mlogloss:2.351788\n",
      "[113]\ttrain-mlogloss:2.199325\teval-mlogloss:2.351802\n",
      "[114]\ttrain-mlogloss:2.198503\teval-mlogloss:2.351734\n",
      "[115]\ttrain-mlogloss:2.197545\teval-mlogloss:2.351681\n",
      "[116]\ttrain-mlogloss:2.196533\teval-mlogloss:2.351647\n",
      "[117]\ttrain-mlogloss:2.195474\teval-mlogloss:2.351610\n",
      "[118]\ttrain-mlogloss:2.194488\teval-mlogloss:2.351587\n",
      "[119]\ttrain-mlogloss:2.193396\teval-mlogloss:2.351357\n",
      "[120]\ttrain-mlogloss:2.192299\teval-mlogloss:2.351305\n",
      "[121]\ttrain-mlogloss:2.191246\teval-mlogloss:2.351255\n",
      "[122]\ttrain-mlogloss:2.190055\teval-mlogloss:2.351184\n",
      "[123]\ttrain-mlogloss:2.188886\teval-mlogloss:2.351124\n",
      "[124]\ttrain-mlogloss:2.187832\teval-mlogloss:2.351218\n",
      "[125]\ttrain-mlogloss:2.186723\teval-mlogloss:2.351222\n",
      "[126]\ttrain-mlogloss:2.185601\teval-mlogloss:2.351119\n",
      "[127]\ttrain-mlogloss:2.184726\teval-mlogloss:2.351111\n",
      "[128]\ttrain-mlogloss:2.183686\teval-mlogloss:2.351184\n",
      "[129]\ttrain-mlogloss:2.182673\teval-mlogloss:2.351048\n",
      "[130]\ttrain-mlogloss:2.181672\teval-mlogloss:2.351034\n",
      "[131]\ttrain-mlogloss:2.180512\teval-mlogloss:2.350952\n",
      "[132]\ttrain-mlogloss:2.179653\teval-mlogloss:2.350955\n",
      "[133]\ttrain-mlogloss:2.178679\teval-mlogloss:2.350958\n",
      "[134]\ttrain-mlogloss:2.177749\teval-mlogloss:2.350839\n",
      "[135]\ttrain-mlogloss:2.176780\teval-mlogloss:2.350876\n",
      "[136]\ttrain-mlogloss:2.175874\teval-mlogloss:2.350870\n",
      "[137]\ttrain-mlogloss:2.174891\teval-mlogloss:2.350899\n",
      "[138]\ttrain-mlogloss:2.173952\teval-mlogloss:2.350889\n",
      "[139]\ttrain-mlogloss:2.172940\teval-mlogloss:2.350885\n",
      "[140]\ttrain-mlogloss:2.171926\teval-mlogloss:2.350870\n",
      "[141]\ttrain-mlogloss:2.171169\teval-mlogloss:2.350978\n",
      "[142]\ttrain-mlogloss:2.170379\teval-mlogloss:2.350978\n",
      "[143]\ttrain-mlogloss:2.169464\teval-mlogloss:2.350975\n",
      "[144]\ttrain-mlogloss:2.168537\teval-mlogloss:2.350995\n",
      "[145]\ttrain-mlogloss:2.167730\teval-mlogloss:2.350996\n",
      "[146]\ttrain-mlogloss:2.166848\teval-mlogloss:2.350937\n",
      "[147]\ttrain-mlogloss:2.165803\teval-mlogloss:2.350929\n",
      "[148]\ttrain-mlogloss:2.164914\teval-mlogloss:2.350821\n",
      "[149]\ttrain-mlogloss:2.163912\teval-mlogloss:2.350784\n",
      "[150]\ttrain-mlogloss:2.162948\teval-mlogloss:2.350796\n",
      "[151]\ttrain-mlogloss:2.162058\teval-mlogloss:2.350798\n",
      "[152]\ttrain-mlogloss:2.161164\teval-mlogloss:2.350745\n",
      "[153]\ttrain-mlogloss:2.160256\teval-mlogloss:2.350687\n",
      "[154]\ttrain-mlogloss:2.159258\teval-mlogloss:2.350770\n",
      "[155]\ttrain-mlogloss:2.158206\teval-mlogloss:2.350758\n",
      "[156]\ttrain-mlogloss:2.157226\teval-mlogloss:2.350741\n",
      "[157]\ttrain-mlogloss:2.156384\teval-mlogloss:2.350716\n",
      "[158]\ttrain-mlogloss:2.155438\teval-mlogloss:2.350634\n",
      "[159]\ttrain-mlogloss:2.154502\teval-mlogloss:2.350660\n",
      "[160]\ttrain-mlogloss:2.153410\teval-mlogloss:2.350805\n",
      "[161]\ttrain-mlogloss:2.152613\teval-mlogloss:2.350815\n",
      "[162]\ttrain-mlogloss:2.151669\teval-mlogloss:2.350791\n",
      "[163]\ttrain-mlogloss:2.150641\teval-mlogloss:2.350847\n",
      "[164]\ttrain-mlogloss:2.149842\teval-mlogloss:2.350818\n",
      "[165]\ttrain-mlogloss:2.148760\teval-mlogloss:2.350806\n",
      "[166]\ttrain-mlogloss:2.147884\teval-mlogloss:2.350824\n",
      "[167]\ttrain-mlogloss:2.146943\teval-mlogloss:2.350807\n",
      "[168]\ttrain-mlogloss:2.146023\teval-mlogloss:2.350875\n",
      "[169]\ttrain-mlogloss:2.145008\teval-mlogloss:2.350884\n",
      "[170]\ttrain-mlogloss:2.144024\teval-mlogloss:2.350873\n",
      "[171]\ttrain-mlogloss:2.143052\teval-mlogloss:2.350851\n",
      "[172]\ttrain-mlogloss:2.142385\teval-mlogloss:2.350914\n",
      "[173]\ttrain-mlogloss:2.141563\teval-mlogloss:2.350940\n",
      "[174]\ttrain-mlogloss:2.140821\teval-mlogloss:2.351049\n",
      "[175]\ttrain-mlogloss:2.139925\teval-mlogloss:2.351068\n",
      "[176]\ttrain-mlogloss:2.139094\teval-mlogloss:2.351110\n",
      "[177]\ttrain-mlogloss:2.138279\teval-mlogloss:2.351063\n",
      "[178]\ttrain-mlogloss:2.137624\teval-mlogloss:2.351151\n",
      "[179]\ttrain-mlogloss:2.136827\teval-mlogloss:2.351203\n",
      "[180]\ttrain-mlogloss:2.136031\teval-mlogloss:2.351181\n",
      "[181]\ttrain-mlogloss:2.135139\teval-mlogloss:2.351280\n",
      "[182]\ttrain-mlogloss:2.134191\teval-mlogloss:2.351211\n",
      "[183]\ttrain-mlogloss:2.133323\teval-mlogloss:2.351240\n",
      "[184]\ttrain-mlogloss:2.132734\teval-mlogloss:2.351275\n",
      "[185]\ttrain-mlogloss:2.132090\teval-mlogloss:2.351330\n",
      "[186]\ttrain-mlogloss:2.131204\teval-mlogloss:2.351358\n",
      "[187]\ttrain-mlogloss:2.130290\teval-mlogloss:2.351335\n",
      "[188]\ttrain-mlogloss:2.129397\teval-mlogloss:2.351366\n",
      "[189]\ttrain-mlogloss:2.128558\teval-mlogloss:2.351344\n",
      "[190]\ttrain-mlogloss:2.127713\teval-mlogloss:2.351299\n",
      "[191]\ttrain-mlogloss:2.126898\teval-mlogloss:2.351295\n",
      "[192]\ttrain-mlogloss:2.125974\teval-mlogloss:2.351302\n",
      "[193]\ttrain-mlogloss:2.125290\teval-mlogloss:2.351390\n",
      "[194]\ttrain-mlogloss:2.124429\teval-mlogloss:2.351475\n",
      "[195]\ttrain-mlogloss:2.123765\teval-mlogloss:2.351462\n",
      "[196]\ttrain-mlogloss:2.122955\teval-mlogloss:2.351413\n",
      "[197]\ttrain-mlogloss:2.122250\teval-mlogloss:2.351480\n",
      "[198]\ttrain-mlogloss:2.121275\teval-mlogloss:2.351498\n",
      "[199]\ttrain-mlogloss:2.120575\teval-mlogloss:2.351479\n",
      "[200]\ttrain-mlogloss:2.119798\teval-mlogloss:2.351499\n",
      "[201]\ttrain-mlogloss:2.118917\teval-mlogloss:2.351676\n",
      "[202]\ttrain-mlogloss:2.118150\teval-mlogloss:2.351799\n",
      "[203]\ttrain-mlogloss:2.117399\teval-mlogloss:2.351813\n",
      "[204]\ttrain-mlogloss:2.116676\teval-mlogloss:2.351744\n",
      "[205]\ttrain-mlogloss:2.115906\teval-mlogloss:2.351784\n",
      "[206]\ttrain-mlogloss:2.115121\teval-mlogloss:2.351829\n",
      "[207]\ttrain-mlogloss:2.114311\teval-mlogloss:2.351888\n",
      "[208]\ttrain-mlogloss:2.113546\teval-mlogloss:2.351943\n",
      "Stopping. Best iteration:\n",
      "[158]\ttrain-mlogloss:2.155438\teval-mlogloss:2.350634\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n",
      "Predict test set...\n",
      "Training time: 2.9 minutes\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import xgboost as xgb\n",
    "import random\n",
    "import zipfile\n",
    "import time\n",
    "import shutil\n",
    "from sklearn import cross_validation, metrics\n",
    "import re\n",
    "\n",
    "random.seed(2016)\n",
    "    \n",
    "def run_xgb(train, test, features, target, random_state=0):\n",
    "    eta = 0.1\n",
    "    max_depth = 5\n",
    "    subsample = 0.7\n",
    "    colsample_bytree = 0.7\n",
    "    start_time = time.time()\n",
    "\n",
    "    print('XGBoost params. ETA: {}, MAX_DEPTH: {}, SUBSAMPLE: {}, COLSAMPLE_BY_TREE: {}'.format(\n",
    "            eta, max_depth, subsample, colsample_bytree))\n",
    "    params = {\n",
    "        \"objective\": \"multi:softprob\",\n",
    "        \"num_class\": 12,\n",
    "        \"booster\" : \"gbtree\",\n",
    "        \"eval_metric\": \"mlogloss\",\n",
    "        \"eta\": eta,\n",
    "        \"max_depth\": max_depth,\n",
    "        \"subsample\": subsample,\n",
    "        \"colsample_bytree\": colsample_bytree,\n",
    "        \"silent\": 1,\n",
    "        \"seed\": random_state,\n",
    "    }\n",
    "    num_boost_round = 500\n",
    "    early_stopping_rounds = 50\n",
    "    test_size = 0.3\n",
    "\n",
    "    #X_train, X_valid = train_test_split(train, test_size=test_size, random_state=random_state)\n",
    "    X_train, X_valid, y_train, y_valid = cross_validation.train_test_split(\n",
    "                        train, train.group, test_size=0.3, random_state=0)\n",
    "    \n",
    "    print('Length train:', len(X_train.index))\n",
    "    print('Length valid:', len(X_valid.index))\n",
    "#     y_train = X_train[target]\n",
    "#     y_valid = X_valid[target]\n",
    "    dtrain = xgb.DMatrix(X_train[features], y_train)\n",
    "    dvalid = xgb.DMatrix(X_valid[features], y_valid)\n",
    "\n",
    "    watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "    gbm = xgb.train(params, dtrain, num_boost_round, evals=watchlist, \n",
    "                    early_stopping_rounds=early_stopping_rounds, verbose_eval=True)\n",
    "\n",
    "    print(\"Validating...\")\n",
    "    check = gbm.predict(xgb.DMatrix(X_valid[features]), ntree_limit=gbm.best_iteration)\n",
    "    score = log_loss(y_valid.tolist(), check)\n",
    "\n",
    "    print(\"Predict test set...\")\n",
    "    test_prediction = gbm.predict(xgb.DMatrix(test[features]), ntree_limit=gbm.best_iteration)\n",
    "\n",
    "    print('Training time: {} minutes'.format(round((time.time() - start_time)/60, 2)))\n",
    "    return test_prediction.tolist(), score\n",
    "\n",
    "\n",
    "def create_submission(score, test, prediction):\n",
    "    # Make Submission\n",
    "    now = datetime.datetime.now()\n",
    "    sub_file = 'submission_' + str(score) + '_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "    print('Writing submission: ', sub_file)\n",
    "    f = open(sub_file, 'w')\n",
    "    f.write('device_id,F23-,F24-26,F27-28,F29-32,F33-42,F43+,M22-,M23-26,M27-28,M29-31,M32-38,M39+\\n')\n",
    "    total = 0\n",
    "    test_val = test['device_id'].values\n",
    "    for i in range(len(test_val)):\n",
    "        str1 = str(test_val[i])\n",
    "        for j in range(12):\n",
    "            str1 += ',' + str(prediction[i][j])\n",
    "        str1 += '\\n'\n",
    "        total += 1\n",
    "        f.write(str1)\n",
    "    f.close()\n",
    "\n",
    "\n",
    "\n",
    "def read_train_test():\n",
    "\n",
    "    events_acc = pd.read_csv(\"eventApps.csv\", low_memory=False, \n",
    "                                      dtype= {'device_id': np.str})\n",
    "\n",
    "    # Phone brand\n",
    "    print('Read brands...')\n",
    "    pbd = pd.read_csv(\"./data/phone_brand_device_model.csv\", dtype={'device_id': np.str})\n",
    "    pbd.drop_duplicates('device_id', keep='first', inplace=True)\n",
    "    pbd = map_column(pbd, 'phone_brand')\n",
    "    pbd = map_column(pbd, 'device_model')\n",
    "    \n",
    "    #Timestamp\n",
    "    \n",
    "\n",
    "    # Train\n",
    "    print('Read train...')\n",
    "    train = pd.read_csv(\"./data/gender_age_train.csv\", dtype={'device_id': np.str})\n",
    "    train = map_column(train, 'group')\n",
    "    train = train.drop(['age'], axis=1)\n",
    "    train = train.drop(['gender'], axis=1)\n",
    "    train = pd.merge(train, pbd, how='left', on='device_id', left_index=True)\n",
    "    train = pd.merge(train, events_acc, how='left', on='device_id', left_index=True)\n",
    "    train.fillna(-1, inplace=True)\n",
    "    \n",
    "    # Test\n",
    "    print('Read test...')\n",
    "    test = pd.read_csv(\"./data/gender_age_test.csv\", dtype={'device_id': np.str})\n",
    "    test = pd.merge(test, pbd, how='left', on='device_id', left_index=True)\n",
    "    test = pd.merge(test, events_acc, how='left', on='device_id', left_index=True)\n",
    "    test.fillna(-1, inplace=True)\n",
    "    \n",
    "    \n",
    "    # Features\n",
    "    features = list(test.columns.values)\n",
    "    #features = ['phone_brand','device_model']\n",
    "    features.remove('device_id')\n",
    "    #features.remove('event_id')\n",
    "    #features.remove('timestamp')\n",
    "\n",
    "    return train, test, features\n",
    "\n",
    "\n",
    "train, test, features = read_train_test()\n",
    "print('Length of train: ', len(train))\n",
    "print('Length of test: ', len(test))\n",
    "print('Features [{}]: {}'.format(len(features), sorted(features)))\n",
    "test_prediction, score = run_xgb(train, test, features, 'group')\n",
    "\n",
    "#create_submission(score, test, test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%qtconsole --ConsoleWidget.font_family=\"Menlo\" --ConsoleWidget.font_size=14"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
